---
title: "p8105_hw2_fy2297"
output: github_document
---

```{r}
library(tidyverse)
library(dplyr)
library(readxl)
```


# Problem 1
```{r}
nyc_transit = read_csv("NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>% 
  janitor::clean_names() %>% 
  select(line:entry, vending, ada) %>% 
  mutate(
    entry = if_else(is.na(entry), FALSE, TRUE)
  )
```

```{r echo = FALSE}
# data needed for description
row_nyc_transit = nrow(nyc_transit)
col_nyc_transit = ncol(nyc_transit)

# data needed for questions
distinct_station = distinct(nyc_transit,line, station_name, .keep_all = TRUE)
num_distinct_station = nrow(distinct_station)
num_ada_compliant = sum(distinct_station$ada, na.rm = TRUE)
num_no_vending_allow = sum(distinct_station$vending == 'NO')
pro_no_vending_allow = (num_no_vending_allow/row_nyc_transit) * 100
```
inline description about data:
First, import the data as csv file, and clean it using janitor package. Then, select columns that contain variables as required, and convert the type of entry variable from character to logical using if_else function.
The cleaned nyc_transit dataframe has line, station name, station latitude/longitude, routes served, entry, entrance type, vending and ada as variables.
The dimension of the resulting data is `r row_nyc_transit` * `r col_nyc_transit`. The data is not tidy enough because some of the stations are not distinct, we still need more cleaning steps to make it tidier.

questions:
1. There are `r num_distinct_station` here in New York.
2. There are `r num_ada_compliant` stations are ADA compliant.
3. The proportion of station entrances/exits without vending allow is `r pro_no_vending_allow`%.

# Problem 2
```{r}
# clean and tidy the mr_trash_wheel sheet
mr_trash_wheel = read_excel("Trash-Wheel-Collection-Totals-7-2020-2.xlsx", 
                            sheet = 1) %>% 
  janitor::clean_names() %>% 
  select(dumpster:homes_powered) %>% 
  mutate(sports_balls = as.integer(sports_balls)) %>% 
  mutate(dumpster = as.double(dumpster)) %>% 
  filter(is.double(dumpster)==TRUE) %>% 
  drop_na(dumpster) %>% 
  mutate(sheet_origin = "mr_trash_wheel")

# clean and tidy the professor_trash_wheel sheet
pro_trash_wheel = read_excel("Trash-Wheel-Collection-Totals-7-2020-2.xlsx",
                             sheet = 2) %>% 
  janitor::clean_names() %>% 
  drop_na(dumpster) %>% 
  mutate(sports_balls = as.integer(sports_balls)) %>% 
  mutate(sheet_origin = "pro_trash_wheel")

# combine these two sheets and clean/tidy it
com_trash_wheel = bind_rows(mr_trash_wheel, pro_trash_wheel) %>% 
  janitor::clean_names() %>% 
  select(sheet_origin, everything())

```

```{r echo = FALSE}
# data needed for combined dataset descriptions
num_obs = nrow(com_trash_wheel)
pro_total_weight_tons = sum(pro_trash_wheel[, 'weight_tons'])
mr_trash_wheel_2020 = filter(mr_trash_wheel, year == 2020)
mr_total_sports_balls_2020 = sum(mr_trash_wheel_2020[, 'sports_balls']) 
```
inline description about data:
The resulting dataset (combined) has `r num_obs` observations in total.
The key variables are 'sheet_origin' because it tells about where the data comes from after combination, 'month' and 'year' are also important because we can know exactly when the data was collected.
The total weight of trash collected by Professor Trash Wheel is `r pro_total_weight_tons`.
The total number of sports balls collected by Mr. Trash Wheel in 2020 is `r mr_total_sports_balls_2020`.


# Problem 3
```{r}
# clean the data in pols-month.csv
pols_month = read_csv("./data3/pols-month.csv") %>% 
  janitor::clean_names() %>% 
  separate(mon, into = c("year", "month", "day"), sep = '-') %>% 
  select(-day, -prez_dem, -prez_gop) %>% 
  mutate(
    month = recode(month, `01` = "January", `02` = "Feburary", `03` = "March", `04` = "April", `05` = "May", `06` = "June", `07` = "July", `08` = "August", `09` = "September", `10` = "October", `11` = "November", `12` = "December")
  ) %>% 
  mutate(
    president = gov_gop + sen_gop + rep_gop + gov_dem + sen_dem + rep_dem
  )

# clean the data in snp.csv
snp = read_csv("./data3/snp.csv") %>% 
  janitor::clean_names() %>% 
  separate(date, into = c("month", "day", "year"), sep = '/') %>% 
  select(-day) %>%
  mutate(
    month = recode(month, `1` = "January", `2` = "Feburary", `3` = "March", `4` = "April", `5` = "May", `6` = "June", `7` = "July", `8` = "August", `9` = "September", `10` = "October", `11` = "November", `12` = "December")
  ) %>% 
  select(year, month, everything()) 

# clean the data in unemployment.csv
unemployment = read_csv("./data3/unemployment.csv") %>% 
  janitor::clean_names() %>% 
  pivot_longer(
    jan:dec,
    names_to = "month",
    values_to = "unemployment rate"
  ) %>% 
  mutate(
    month = recode(month, `jan` = "January", `feb` = "Feburary", `mar` = "March", `apr` = "April", `may` = "May", `jun` = "June", `jul` = "July", `aug` = "August", `sep` = "September", `oct` = "October", `nov` = "November", `dec` = "December")
  ) 

# combine the datasets as desired
com_data = full_join(pols_month, snp, by = "year", "month")
```
inline description about data:
The pols-month.csv contains
The snp.csv contains
The unemployment.csv contains
The combined resulting dataset










